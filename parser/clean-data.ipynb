{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraped Political Reddit Posts\n",
    "- r/hasan_piker\n",
    "- r/destin\n",
    "- r/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Post:\n",
    "    def __init__(self, data):\n",
    "        self.subreddit = data.get(\"subreddit\", \"\")\n",
    "        self.subreddit_id = data.get(\"subreddit_id\", \"\")\n",
    "        self.title = data.get(\"title\", \"\")\n",
    "        self.selftext = data.get(\"selftext\", \"\")\n",
    "        self.author = data.get(\"author\", \"\")\n",
    "        self.author_flair = data.get(\"author_flair_text\", \"\")\n",
    "        self.score = data.get(\"score\", 0)\n",
    "        self.upvote_ratio = data.get(\"upvote_ratio\", 0.0)\n",
    "        self.num_comments = data.get(\"num_comments\", 0)\n",
    "        self.created_utc = data.get(\"created_utc\", 0)\n",
    "        self.link_flair = data.get(\"link_flair_text\", \"\")\n",
    "        self.url = data.get(\"url\", \"\")\n",
    "        self.total_awards = data.get(\"total_awards_received\", 0)\n",
    "        self.controversiality = data.get(\"controversiality\", 0)\n",
    "        self.num_reports = data.get(\"num_reports\", 0)\n",
    "        self.comments = []\n",
    "\n",
    "    def add_comment(self, comment_data):\n",
    "        self.comments.append(Comment(comment_data))\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"subreddit\": self.subreddit,\n",
    "            \"subreddit_id\": self.subreddit_id,\n",
    "            \"title\": self.title,\n",
    "            \"selftext\": self.selftext,\n",
    "            \"author\": self.author,\n",
    "            \"author_flair\": self.author_flair,\n",
    "            \"score\": self.score,\n",
    "            \"upvote_ratio\": self.upvote_ratio,\n",
    "            \"num_comments\": self.num_comments,\n",
    "            \"created_utc\": self.created_utc,\n",
    "            \"link_flair\": self.link_flair,\n",
    "            \"url\": self.url,\n",
    "            \"total_awards\": self.total_awards,\n",
    "            \"controversiality\": self.controversiality,\n",
    "            \"num_reports\": self.num_reports,\n",
    "            \"comments\": [comment.to_dict() for comment in self.comments]\n",
    "        }\n",
    "\n",
    "class Comment:\n",
    "    def __init__(self, data):\n",
    "        self.author = data.get(\"author\", \"\")\n",
    "        self.author_flair = data.get(\"author_flair_text\", \"\")\n",
    "        self.body = data.get(\"body\", \"\")\n",
    "        self.score = data.get(\"score\", 0)\n",
    "        self.depth = data.get(\"depth\", 0)\n",
    "        self.controversiality = data.get(\"controversiality\", 0)\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"author\": self.author,\n",
    "            \"author_flair\": self.author_flair,\n",
    "            \"body\": self.body,\n",
    "            \"score\": self.score,\n",
    "            \"depth\": self.depth,\n",
    "            \"controversiality\": self.controversiality\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to help us clean parse and clean the raw json file (~4gb of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_clean_json(input_file, output_file, chunk_size=1000):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            # Attempt to load the entire content as a single JSON array\n",
    "            json_data = json.load(f)\n",
    "            if isinstance(json_data, list):\n",
    "                process_json_array(json_data, output_file, chunk_size)\n",
    "            else:\n",
    "                raise ValueError(\"Expected a JSON array or line-delimited JSON\")\n",
    "        except json.JSONDecodeError:\n",
    "            f.seek(0)\n",
    "            process_line_by_line(f, output_file, chunk_size)\n",
    "\n",
    "def process_json_array(json_data, output_file, chunk_size):\n",
    "    with open(output_file, 'w', encoding='utf-8') as out:\n",
    "        # Create chunks and show progress\n",
    "        for i in tqdm(range(0, len(json_data), chunk_size), desc=\"Processing JSON array\"):\n",
    "            chunk = json_data[i:i + chunk_size]\n",
    "            for item in chunk:\n",
    "                cleaned_data = clean_post_data(item)\n",
    "                json.dump(cleaned_data, out)\n",
    "                out.write('\\n')\n",
    "\n",
    "def process_line_by_line(f, output_file, chunk_size):\n",
    "    with open(output_file, 'w', encoding='utf-8') as out:\n",
    "        lines = f.readlines()\n",
    "        for i in tqdm(range(0, len(lines), chunk_size), desc=\"Processing JSON lines\"):\n",
    "            chunk = lines[i:i + chunk_size]\n",
    "            for line in chunk:\n",
    "                try:\n",
    "                    json_data = json.loads(line.strip())\n",
    "                    cleaned_data = clean_post_data(json_data)\n",
    "                    json.dump(cleaned_data, out)\n",
    "                    out.write('\\n')\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Skipping invalid JSON line: {line}\")\n",
    "\n",
    "def clean_post_data(json_data):\n",
    "    post_data = json_data.get(\"data\", {})\n",
    "    comments_data = json_data.get(\"comments\", {})\n",
    "\n",
    "    post = Post(post_data)\n",
    "    for _, comment_data in comments_data.items():\n",
    "        post.add_comment(comment_data)\n",
    "\n",
    "    return post.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data and save to an output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "INPUT_FILE = './json/input/posts-11-13-2024.json'\n",
    "OUTPUT_FILE = './json/output/cleaned-posts-11-13-2024.json'\n",
    "parse_and_clean_json(INPUT_FILE, OUTPUT_FILE, chunk_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset into dataframe\n",
    "then show it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(OUTPUT_FILE, lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only keep posts from the subreddit we're finetuning a model for\n",
    "### change this with whatever you wanna finetune on\n",
    "df = df[df['subreddit'] == 'Hasan_Piker']\n",
    "#### or\n",
    "df = df[df['upvote_ratio'] <= 0.5]\n",
    "#### or\n",
    "df = df[df['link_flair'] == 'Politics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['subreddit'] == 'Hasan_Piker']\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "election-crawler-mlEYhPe--py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
