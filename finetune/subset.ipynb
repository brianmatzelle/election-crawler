{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "This notebook is used to create a subset of the dataset for finetuning a GPT-style conversational language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "SUBREDDITS = ['hasan_piker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"brianmatzelle/2024-election-subreddit-threads-643k\", split = \"train\")\n",
    "prefilter_size = len(dataset)\n",
    "\n",
    "from utils import to_k\n",
    "logger.info(f\"Prefilter dataset size: {to_k(prefilter_size)}\")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count the posts in each subreddit\n",
    "subreddit_counts = Counter(post['metadata']['subreddit']['name'] for post in dataset)\n",
    "# Sort by the number of posts in descending order\n",
    "ranked_subreddits = sorted(subreddit_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the ranking\n",
    "for i, (subreddit, count) in enumerate(ranked_subreddits, start=1):\n",
    "    for post in dataset:\n",
    "        if post['metadata']['subreddit']['name'] == subreddit:\n",
    "            subscribers = post['metadata']['subreddit']['subscribers']\n",
    "    print(f\"{i}. r/{subreddit}: {count} posts, {subscribers} subscribers\")\n",
    "\n",
    "# Optionally log the results if needed\n",
    "logger.info(f\"Subreddit ranking:\\n{ranked_subreddits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show most controversial posts\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "# Create a dictionary to store the posts for each subreddit\n",
    "subreddit_posts = defaultdict(list)\n",
    "most_controversial_posts = []\n",
    "highest_score = 0\n",
    "\n",
    "for post in dataset:\n",
    "    controversiality = post['metadata']['controversiality']\n",
    "    subreddit = post['subreddit']\n",
    "    \n",
    "    # Add the post to the corresponding subreddit list\n",
    "    subreddit_posts[subreddit].append((post, controversiality))\n",
    "    \n",
    "    # Check if this post has the highest controversiality score so far\n",
    "    if controversiality > highest_score:\n",
    "        highest_score = controversiality\n",
    "        most_controversial_posts = [post]  # Reset the list to include only this post\n",
    "    elif controversiality == highest_score:\n",
    "        most_controversial_posts.append(post)  # Add to the list if the score matches the highest\n",
    "\n",
    "# Sort the posts in each subreddit by controversiality in descending order\n",
    "for subreddit, posts in subreddit_posts.items():\n",
    "    subreddit_posts[subreddit] = sorted(posts, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the results\n",
    "print(\"Most Controversial Posts Across All Subreddits:\")\n",
    "pprint(most_controversial_posts)\n",
    "\n",
    "print(\"\\nMost Controversial Posts By Subreddit:\")\n",
    "for subreddit, posts in subreddit_posts.items():\n",
    "    print(f\"Subreddit: {subreddit}\")\n",
    "    pprint([post[0] for post in posts[:5]])  # Display top 5 most controversial posts per subreddit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(lambda x: x['metadata']['subreddit']['name'] in SUBREDDITS)\n",
    "logger.info(f\"Filtered {to_k(prefilter_size - len(dataset))} posts from the dataset\")\n",
    "del prefilter_size\n",
    "\n",
    "logger.info(f\"Dataset size: {to_k(len(dataset))} posts\")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unsloth_env)",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
