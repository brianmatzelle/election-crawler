{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "This notebook is used to create a base dataset of reddit conversations, so that it can be filtered and subset in the future.\n",
    "\n",
    "### To Do\n",
    "- Add custom metadata based on analysis of the conversation\n",
    "  - [X] normalized controversiality\n",
    "  - [ ] fix normalized contr., currently some values are greater than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "# Description: Configuration for the dataset module, could eventually be used as flags\n",
    "# HUGGINGFACE_USERNAME = 'BinghamtonUniversity'\n",
    "HUGGINGFACE_USERNAME = 'brianmatzelle'\n",
    "\n",
    "# change if you know what you're doing\n",
    "RAW_DATA_FILE_NAME = 'posts-11-13-2024'\n",
    "\n",
    "# DONT CHANGE\n",
    "RAW_DATA_FILE = f'data/raw/{RAW_DATA_FILE_NAME}.json'\n",
    "PROCESSED_DATA_FILE = f'data/processed/{RAW_DATA_FILE_NAME}-processed.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-04 12:40:39.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mLoaded 54215 rows from data/processed/posts-11-13-2024-processed.json\u001b[0m\n",
      "\u001b[32m2024-12-04 12:40:39.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mConverted json to pandas DataFrame with 54215 rows\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>downs</th>\n",
       "      <th>name</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>ups</th>\n",
       "      <th>removed_by_category</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>...</th>\n",
       "      <th>no_follow</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>send_replies</th>\n",
       "      <th>is_video</th>\n",
       "      <th>deleted</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1dx1b0z</td>\n",
       "      <td>Destiny</td>\n",
       "      <td></td>\n",
       "      <td>New Vegan</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_1dx1b0z</td>\n",
       "      <td>0.95</td>\n",
       "      <td>121</td>\n",
       "      <td>None</td>\n",
       "      <td>Shitpost</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1720304607</td>\n",
       "      <td>None</td>\n",
       "      <td>TuningsGaming</td>\n",
       "      <td>2</td>\n",
       "      <td>248289</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'id': 'lbyv8mn', 'total_awards_received': 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id subreddit selftext      title  downs        name  upvote_ratio  \\\n",
       "0  1dx1b0z   Destiny           New Vegan      0  t3_1dx1b0z          0.95   \n",
       "\n",
       "   ups removed_by_category link_flair_text  ...  no_follow  created_utc  \\\n",
       "0  121                None        Shitpost  ...      False   1720304607   \n",
       "\n",
       "  author_flair_text         author num_comments  subreddit_subscribers  \\\n",
       "0              None  TuningsGaming            2                 248289   \n",
       "\n",
       "   send_replies is_video deleted  \\\n",
       "0          True    False   False   \n",
       "\n",
       "                                            comments  \n",
       "0  [{'id': 'lbyv8mn', 'total_awards_received': 0,...  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from loguru import logger\n",
    "\n",
    "with open(PROCESSED_DATA_FILE, 'r') as f:\n",
    "  data = json.load(f)\n",
    "logger.info(f\"Loaded {len(data)} rows from {PROCESSED_DATA_FILE}\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "del data\n",
    "prefilter_len = len(df)\n",
    "logger.info(f\"Converted json to pandas DataFrame with {prefilter_len} rows\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-04 12:40:39.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mDataset size (posts): 54k\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['destiny' 'hasan_piker' 'politics' 'vaushv' 'millenials' 'news'\n",
      " 'worldnews' 'economics' 'socialism' 'conservative' 'libertarian'\n",
      " 'neoliberal' 'republican' 'democrats' 'progressive' 'daverubin'\n",
      " 'jordanpeterson' 'samharris' 'joerogan' 'thedavidpakmanshow' 'benshapiro'\n",
      " 'themajorityreport' 'seculartalk']\n"
     ]
    }
   ],
   "source": [
    "# alter columns so they're easier to work with\n",
    "df['subreddit'] = df['subreddit'].str.lower()\n",
    "\n",
    "# Show some values that might be helpful for customizing configuration\n",
    "print(df['subreddit'].unique())\n",
    "\n",
    "from utils import to_k\n",
    "posts_count = to_k(len(df))\n",
    "logger.info(f\"Dataset size (posts): {posts_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop through posts and create conversations by alternating user/assistant with every comment/reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do:\n",
    "- Generate synthetic data for threads that end in a user message. Currently we just remove this valuable data :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is straight from hell\n",
    "\n",
    "from typing import Dict, Generator, List, Tuple\n",
    "def Turn(role: str, content: str, metadata: Dict) -> Dict[str, str]:\n",
    "  return {\n",
    "    'role': role,\n",
    "    'content': content,\n",
    "    'metadata': metadata\n",
    "  }\n",
    "\n",
    "def get_comment_metadata(comment: Dict) -> Dict:\n",
    "  return {\n",
    "    \"score\": comment.get('score', None),\n",
    "    \"upvotes\": comment.get('ups', None),\n",
    "    \"downvotes\": comment.get('downs', None),\n",
    "    \"controversiality\": comment.get('controversiality', None),\n",
    "    \"created_utc\": comment.get('created_utc', None),\n",
    "    \"author\": comment.get('author', None),\n",
    "    \"no_follow\": comment.get('no_follow', None),\n",
    "    \"total_awards_received\": comment.get('total_awards_received', None),\n",
    "    \"is_submitter\": comment.get('is_submitter', None),\n",
    "  }\n",
    "\n",
    "def traverse_thread(comment: Dict, c_sum: int, role: str = 'assistant') -> Generator[Tuple[List[Dict[str, str]], int], None, None]:\n",
    "    \"\"\"\n",
    "    Recursively traverse a comment thread and yield each individual thread.\n",
    "    \"\"\"\n",
    "    if role not in {'assistant', 'user'}:\n",
    "        raise ValueError(\"role must be 'assistant' or 'user'\")\n",
    "    \n",
    "    if not comment.get('body'):\n",
    "        return\n",
    "    \n",
    "    if comment['body'] == '[deleted]' or comment['body'] == '[removed]':\n",
    "        return\n",
    "  \n",
    "    metadata = get_comment_metadata(comment)\n",
    "    # Start the thread with the current comment\n",
    "    current_thread = [Turn(role, comment['body'], metadata)]\n",
    "\n",
    "    # Add controversiality only for the current comment\n",
    "    current_c_sum = c_sum + comment.get('controversiality')\n",
    "    \n",
    "    # If no replies, yield the current thread with current_c_sum\n",
    "    if not comment.get('replies'):\n",
    "        # if the last message is from the user, remove it and subtract the controversiality\n",
    "        if role == 'user':\n",
    "            current_thread.pop()\n",
    "            current_c_sum -= comment.get('controversiality')\n",
    "        yield current_thread, current_c_sum\n",
    "        return\n",
    "    \n",
    "    # Recurse into replies, but pass current_c_sum instead of c_sum\n",
    "    for reply in comment['replies']:\n",
    "        for sub_thread, sub_c_sum in traverse_thread(reply, current_c_sum, 'user' if role == 'assistant' else 'assistant'):\n",
    "            yield current_thread + sub_thread, sub_c_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do\n",
    "- Add custom metadata based on analysis of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_metadata(post_row):\n",
    "  return {\n",
    "    \"subreddit\": {\n",
    "      \"name\": post_row.get(\"subreddit\", None),\n",
    "      \"subscribers\": post_row.get(\"subreddit_subscribers\", None),\n",
    "    },\n",
    "    \"post\": {\n",
    "      \"score\": post_row.get(\"score\", None),\n",
    "      \"upvotes\": post_row.get(\"ups\", None),\n",
    "      \"downvotes\": post_row.get(\"downs\", None),\n",
    "      \"upvote_ratio\": post_row.get(\"upvote_ratio\", None),\n",
    "      \"flair\": post_row.get(\"link_flair_text\", None),\n",
    "      \"author\": post_row.get(\"author\", \"unknown\"),\n",
    "      \"suggested_sort\": post_row.get(\"suggested_sort\", None),\n",
    "      \"title\": post_row.get(\"title\", None),\n",
    "      \"removed_by_category\": post_row.get(\"removed_by_category\", None),\n",
    "      \"created_utc\": post_row.get(\"created_utc\", None),\n",
    "      \"no_follow\": post_row.get(\"no_follow\", None),\n",
    "      \"total_awards_received\": post_row.get(\"total_awards_received\", None),\n",
    "    },\n",
    "    \"controversiality\": 0,\n",
    "    \"normalized_controversiality\": 0\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-04 12:40:52.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mSkipped 2 bad threads\u001b[0m\n",
      "\u001b[32m2024-12-04 12:40:52.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mExtracted 173713 conversations from 54215 posts\u001b[0m\n",
      "\u001b[32m2024-12-04 12:40:52.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mDeleting dataframe from memory since it hoards resources and is no longer needed\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metadata': {'subreddit': {'name': 'neoliberal', 'subscribers': 175832},\n",
       "  'post': {'score': 433,\n",
       "   'upvotes': 433,\n",
       "   'downvotes': 0,\n",
       "   'upvote_ratio': 0.91,\n",
       "   'flair': 'Megathread',\n",
       "   'author': 'dubyahhh',\n",
       "   'suggested_sort': 'new',\n",
       "   'title': 'Biden Megathread V: The Establishment Strikes Back',\n",
       "   'removed_by_category': None,\n",
       "   'created_utc': 1720363953,\n",
       "   'no_follow': False,\n",
       "   'total_awards_received': 0},\n",
       "  'controversiality': 0,\n",
       "  'normalized_controversiality': 0.0},\n",
       " 'conversation': [{'role': 'user',\n",
       "   'content': 'Name is unrelated to anything, just wanted to make a Star Wars joke since these threads seem to never end\\n\\nHonestly just go touch grass, don’t even read anything beyond this, god save your filthy soul if you venture too deep',\n",
       "   'metadata': {'score': 433,\n",
       "    'upvotes': 433,\n",
       "    'downvotes': 0,\n",
       "    'upvote_ratio': 0.91,\n",
       "    'flair': 'Megathread',\n",
       "    'author': 'dubyahhh',\n",
       "    'suggested_sort': 'new',\n",
       "    'title': 'Biden Megathread V: The Establishment Strikes Back',\n",
       "    'removed_by_category': None,\n",
       "    'created_utc': 1720363953,\n",
       "    'no_follow': False,\n",
       "    'total_awards_received': 0}},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"The democratic party will turn out to vote for whomever we replace Biden with, probably Whitmer or someone else we like, Biden doesn't matter, he's cherry picking polls favorable to him when he says stuff like only 3 in 10 democrats wanting to replace him. There's no downside loss to Biden stepping out, only upside, we're going to lose anyway!\\n\\nWhat is with all these blue MAGAs WTF? We're not a personality cult like the GOP! How could people like this obviously senile person? I must just be imagining them.\",\n",
       "   'metadata': {'score': 24,\n",
       "    'upvotes': 24,\n",
       "    'downvotes': 0,\n",
       "    'controversiality': 0,\n",
       "    'created_utc': 1720423023,\n",
       "    'author': 'dutch_connection_uk',\n",
       "    'no_follow': False,\n",
       "    'total_awards_received': 0,\n",
       "    'is_submitter': False}},\n",
       "  {'role': 'user',\n",
       "   'content': 'There is downside to him stepping out, how tf do people think that',\n",
       "   'metadata': {'score': 3,\n",
       "    'upvotes': 3,\n",
       "    'downvotes': 0,\n",
       "    'controversiality': 0,\n",
       "    'created_utc': 1720434277,\n",
       "    'author': 'DaSemicolon',\n",
       "    'no_follow': False,\n",
       "    'total_awards_received': 0,\n",
       "    'is_submitter': False}},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"Well, it is guaranteed that Biden can't win anymore, so it doesn't hurt to roll the dice.\",\n",
       "   'metadata': {'score': 2,\n",
       "    'upvotes': 2,\n",
       "    'downvotes': 0,\n",
       "    'controversiality': 0,\n",
       "    'created_utc': 1720436518,\n",
       "    'author': 'area51cannonfooder',\n",
       "    'no_follow': True,\n",
       "    'total_awards_received': 0,\n",
       "    'is_submitter': False}},\n",
       "  {'role': 'user',\n",
       "   'content': \"No, it actually isn't guaranteed.\",\n",
       "   'metadata': {'score': 3,\n",
       "    'upvotes': 3,\n",
       "    'downvotes': 0,\n",
       "    'controversiality': 0,\n",
       "    'created_utc': 1720437053,\n",
       "    'author': 'PM_ME_ABSOLUTE_UNITZ',\n",
       "    'no_follow': True,\n",
       "    'total_awards_received': 0,\n",
       "    'is_submitter': False}},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Agreed',\n",
       "   'metadata': {'score': 2,\n",
       "    'upvotes': 2,\n",
       "    'downvotes': 0,\n",
       "    'controversiality': 0,\n",
       "    'created_utc': 1720439801,\n",
       "    'author': 'DaSemicolon',\n",
       "    'no_follow': True,\n",
       "    'total_awards_received': 0,\n",
       "    'is_submitter': False}}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import is_post_valid\n",
    "from lib.analysis import normalize_controversiality_rating\n",
    "\n",
    "# set to prevent duplicates which can occur if the final comment is deleted or removed\n",
    "conversations = set()\n",
    "for i, post_row in df.iterrows():\n",
    "    valid, reason = is_post_valid(post_row)\n",
    "    if not valid:\n",
    "        continue\n",
    "\n",
    "    # Prepare metadata\n",
    "    metadata = get_post_metadata(post_row)\n",
    "    \n",
    "    # if the post is deleted or removed, use the first comment as the initial turn (user)\n",
    "    # deleted posts often still have a lot of comments, so we don't want to throw away the whole post\n",
    "    post_turn = []\n",
    "    if not post_row['selftext'] == '[deleted]' or post_row['selftext'] == '[removed]':\n",
    "        post_turn = [Turn('user', post_row['selftext'] if post_row['selftext'] else post_row['title'], metadata=metadata.get('post', {}))]\n",
    "\n",
    "    # first_turn = [Turn('system', f\"You are a redditor in a political subreddit, having a conversation with another redditor about politics.\")] + post_turn\n",
    "    first_turn = post_turn\n",
    "\n",
    "    bad_thread_count = 0\n",
    "    for comment in post_row.get('comments', []):\n",
    "        for thread, controversiality_sum in traverse_thread(comment, c_sum=0, role='assistant' if len(post_turn) > 0 else 'user'):\n",
    "            if len(thread) < 2:\n",
    "                # skip if the thread is it's only the system message\n",
    "                bad_thread_count += 1\n",
    "                continue\n",
    "            # set controversiality metadata\n",
    "            metadata[\"controversiality\"] = controversiality_sum\n",
    "            metadata[\"normalized_controversiality\"] = normalize_controversiality_rating(sum=controversiality_sum, thread_length=len(thread))\n",
    "            # Serialize thread with metadata\n",
    "            serialized_thread = json.dumps({\n",
    "                \"metadata\": metadata,\n",
    "                \"conversation\": first_turn + thread\n",
    "            })\n",
    "            conversations.add(serialized_thread)\n",
    "            \n",
    "# Deserialize conversations back into Python objects if needed\n",
    "conversations = [json.loads(conv) for conv in conversations]\n",
    "logger.info(f\"Skipped {bad_thread_count} bad threads\")\n",
    "logger.info(f\"Extracted {len(conversations)} conversations from {len(df)} posts\")\n",
    "logger.info(f\"Deleting dataframe from memory since it hoards resources and is no longer needed\")\n",
    "del df\n",
    "conversations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "To Do - remove post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing conversations: 100%|██████████| 173713/173713 [00:00<00:00, 954015.03it/s]\n",
      "\u001b[32m2024-12-04 12:40:52.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mRemoved 0 last messages from 173713 conversations\u001b[0m\n",
      "\u001b[32m2024-12-04 12:40:52.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1mRemoved 0 singleton conversations from 173713 conversations\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "last_msg_user_count, singleton_convo_count = 0, 0\n",
    "# Wrap conversations with tqdm\n",
    "for obj in tqdm(conversations, desc=\"Processing conversations\"):\n",
    "    convo = obj['conversation']\n",
    "    # ... rest of the loop content stays the same ...\n",
    "    if convo[-1]['role'] == 'user':\n",
    "        last_msg_user_count += 1\n",
    "        convo.pop()\n",
    "    \n",
    "    if len(convo) == 1:\n",
    "        singleton_convo_count += 1\n",
    "        conversations.remove(obj)\n",
    "\n",
    "    # from convo[1-end], make sure role is alternating between user and assistant\n",
    "    for i in range(1, len(convo)):\n",
    "        if convo[i]['role'] == convo[i-1]['role']:\n",
    "            raise ValueError(f\"Non-alternating roles found in conversation: {convo}\")\n",
    "\n",
    "logger.info(f\"Removed {last_msg_user_count} last messages from {len(conversations)} conversations\")\n",
    "logger.info(f\"Removed {singleton_convo_count} singleton conversations from {len(conversations)} conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-04 12:40:52.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mWriting 173k conversations to data/datasets/2024-election-subreddit-threads-173k(2).json...\u001b[0m\n",
      "\u001b[32m2024-12-04 12:41:04.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mConversations saved to data/datasets/2024-election-subreddit-threads-173k(2).json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Save to JSON file\n",
    "import json\n",
    "\n",
    "name = '2024-election-subreddit-threads'\n",
    "size_str = to_k(len(conversations))\n",
    "from utils import make_dataset_path\n",
    "dataset_path, hf_dataset_name = make_dataset_path(name, size_str)\n",
    "logger.info(f\"Writing {size_str} conversations to {dataset_path}...\")\n",
    "\n",
    "\n",
    "# Create JSON object with metadata and conversation\n",
    "json_obj = []\n",
    "for conversation_data in conversations:\n",
    "    # Each conversation_data should already include metadata and conversation structure\n",
    "    json_obj.append({\n",
    "        \"metadata\": conversation_data.get(\"metadata\", {}),\n",
    "        \"conversations\": conversation_data.get(\"conversation\", [])\n",
    "    })\n",
    "\n",
    "# Save to file\n",
    "with open(dataset_path, 'w') as f:\n",
    "    json.dump(json_obj, f, indent=2)\n",
    "logger.info(f\"Conversations saved to {dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianmatzelle/anaconda3/envs/election/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 173713 examples [00:11, 15226.82 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 174/174 [00:01<00:00, 165.09ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:08<00:00,  8.94s/it]\n"
     ]
    }
   ],
   "source": [
    "# push to huggingface\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('json', data_files=dataset_path)\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv('HF_TOKEN'):\n",
    "  logger.error(\"No Hugging Face token found, not pushing to hub\")\n",
    "else:\n",
    "  dataset.push_to_hub(f\"{HUGGINGFACE_USERNAME}/{hf_dataset_name}\".lower(), token=os.getenv('HF_TOKEN'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (election_env)",
   "language": "python",
   "name": "election_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
